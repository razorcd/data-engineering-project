{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'3.0.3'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristiandugacicu/.local/lib/python2.7/site-packages/pyspark/context.py:227: DeprecationWarning: Support for Python 2 and Python 3 prior to version 3.6 is deprecated as of Spark 3.0. See also the plan for dropping Python 2 support at https://spark.apache.org/news/plan-for-dropping-python-2-support.html.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "  .master(\"local[*]\") \\\n",
    "  .appName(\"taxi_data\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(VendorID,LongType,true),StructField(tpep_pickup_datetime,StringType,true),StructField(tpep_dropoff_datetime,StringType,true),StructField(passenger_count,LongType,true),StructField(trip_distance,DoubleType,true),StructField(RatecodeID,LongType,true),StructField(store_and_fwd_flag,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(payment_type,LongType,true),StructField(fare_amount,DoubleType,true),StructField(extra,DoubleType,true),StructField(mta_tax,DoubleType,true),StructField(tip_amount,DoubleType,true),StructField(tolls_amount,DoubleType,true),StructField(improvement_surcharge,DoubleType,true),StructField(total_amount,DoubleType,true),StructField(congestion_surcharge,DoubleType,true)))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_yellow_pd = pd.read_csv(\"data/raw/yellow/2020/yellow_tripdata_2020_1.csv.gz\", nrows=1000)\n",
    "df_yellow_pd.dtypes\n",
    "\n",
    "# loads Spark schema from Panda schema as an example to edit:\n",
    "spark.createDataFrame(df_yellow_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(VendorID,LongType,true),StructField(lpep_pickup_datetime,StringType,true),StructField(lpep_dropoff_datetime,StringType,true),StructField(store_and_fwd_flag,StringType,true),StructField(RatecodeID,LongType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(passenger_count,LongType,true),StructField(trip_distance,DoubleType,true),StructField(fare_amount,DoubleType,true),StructField(extra,DoubleType,true),StructField(mta_tax,DoubleType,true),StructField(tip_amount,DoubleType,true),StructField(tolls_amount,DoubleType,true),StructField(ehail_fee,DoubleType,true),StructField(improvement_surcharge,DoubleType,true),StructField(total_amount,DoubleType,true),StructField(payment_type,LongType,true),StructField(trip_type,LongType,true),StructField(congestion_surcharge,DoubleType,true)))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_green_pd = pd.read_csv(\"data/raw/green/2020/green_tripdata_2020_1.csv.gz\", nrows=1000)\n",
    "df_green_pd.dtypes\n",
    "\n",
    "# loads Spark schema from Panda schema as an example to edit:\n",
    "spark.createDataFrame(df_green_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "# create Spark schema:\n",
    "\n",
    "yellow_schema = types.StructType([\n",
    "    types.StructField(\"VendorID\", types.IntegerType(), True),\n",
    "    types.StructField(\"tpep_pickup_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"tpep_dropoff_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"passenger_count\", types.IntegerType(), True),\n",
    "    types.StructField(\"trip_distance\", types.DoubleType(), True),\n",
    "    types.StructField(\"store_and_fwd_flag\", types.StringType(), True),\n",
    "    types.StructField(\"RatecodeID\", types.IntegerType(), True),\n",
    "    types.StructField(\"PULocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"DOLocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"payment_type\", types.IntegerType(), True),\n",
    "    types.StructField(\"fare_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"extra\", types.DoubleType(), True),\n",
    "    types.StructField(\"mta_tax\", types.DoubleType(), True),\n",
    "    types.StructField(\"tip_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"tolls_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"improvement_surcharge\", types.DoubleType(), True),\n",
    "    types.StructField(\"total_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"congestion_surcharge\", types.DoubleType(), True)\n",
    "])\n",
    "\n",
    "green_schema = types.StructType([\n",
    "    types.StructField(\"VendorID\", types.IntegerType(), True),\n",
    "    types.StructField(\"lpep_pickup_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"lpep_dropoff_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"passenger_count\", types.IntegerType(), True),\n",
    "    types.StructField(\"trip_distance\", types.DoubleType(), True),\n",
    "    types.StructField(\"store_and_fwd_flag\", types.StringType(), True),\n",
    "    types.StructField(\"RatecodeID\", types.IntegerType(), True),\n",
    "    types.StructField(\"PULocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"DOLocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"payment_type\", types.IntegerType(), True),\n",
    "    types.StructField(\"fare_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"extra\", types.DoubleType(), True),\n",
    "    types.StructField(\"mta_tax\", types.DoubleType(), True),\n",
    "    types.StructField(\"tip_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"tolls_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"improvement_surcharge\", types.DoubleType(), True),\n",
    "    types.StructField(\"total_amount\", types.DoubleType(), True),\n",
    "    types.StructField(\"congestion_surcharge\", types.DoubleType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing yearn: 2020, month: 1\n",
      "Executing yearn: 2020, month: 2\n",
      "Executing yearn: 2020, month: 3\n",
      "Executing yearn: 2020, month: 4\n",
      "Executing yearn: 2020, month: 5\n",
      "Executing yearn: 2020, month: 6\n",
      "Executing yearn: 2020, month: 7\n",
      "Executing yearn: 2020, month: 8\n",
      "Executing yearn: 2020, month: 9\n",
      "Executing yearn: 2020, month: 10\n",
      "Executing yearn: 2020, month: 11\n",
      "Executing yearn: 2020, month: 12\n",
      "Executing yearn: 2021, month: 1\n",
      "Executing yearn: 2021, month: 2\n",
      "Executing yearn: 2021, month: 3\n",
      "Executing yearn: 2021, month: 4\n",
      "Executing yearn: 2021, month: 5\n",
      "Executing yearn: 2021, month: 6\n",
      "Executing yearn: 2021, month: 7\n",
      "Executing yearn: 2021, month: 8\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/home/cristiandugacicu/projects/personal/de-zoomcamp/course5/notebooks/data/raw/yellow/2021/*2021_8.*;",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a61dc1ff25d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Executing yearn: {}, month: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#         print(\"data/raw/yellow/{year}/*{year}_{month}.*\".format(year=year, month=month))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdf_yellow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myellow_schema\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/raw/yellow/{year}/*{year}_{month}.*\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdf_yellow\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/pq/yellow/{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristiandugacicu/.local/lib/python2.7/site-packages/pyspark/sql/readwriter.pyc\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristiandugacicu/.local/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristiandugacicu/.local/lib/python2.7/site-packages/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristiandugacicu/.local/lib/python2.7/site-packages/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/home/cristiandugacicu/projects/personal/de-zoomcamp/course5/notebooks/data/raw/yellow/2021/*2021_8.*;"
     ]
    }
   ],
   "source": [
    "# create parquet files:\n",
    "\n",
    "for year in (2020, 2021):\n",
    "    for month in range(1,13):\n",
    "        print(\"Executing year: {}, month: {}\".format(year,month))\n",
    "#         print(\"data/raw/yellow/{year}/*{year}_{month}.*\".format(year=year, month=month))\n",
    "        df_yellow = spark.read \\\n",
    "          .option(\"header\", \"true\") \\\n",
    "          .schema(yellow_schema) \\\n",
    "          .csv(\"data/raw/yellow/{year}/*{year}_{month}.*\".format(year=year,month=month))\n",
    "\n",
    "        df_yellow \\\n",
    "            .repartition(4) \\\n",
    "            .write \\\n",
    "            .parquet(\"data/pq/yellow/{}/{}\".format(year,month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing year: 2020, month: 1\n",
      "Executing year: 2020, month: 2\n",
      "Executing year: 2020, month: 3\n",
      "Executing year: 2020, month: 4\n",
      "Executing year: 2020, month: 5\n",
      "Executing year: 2020, month: 6\n",
      "Executing year: 2020, month: 7\n",
      "Executing year: 2020, month: 8\n",
      "Executing year: 2020, month: 9\n",
      "Executing year: 2020, month: 10\n",
      "Executing year: 2020, month: 11\n",
      "Executing year: 2020, month: 12\n",
      "Executing year: 2021, month: 1\n",
      "Executing year: 2021, month: 2\n",
      "Executing year: 2021, month: 3\n",
      "Executing year: 2021, month: 4\n",
      "Executing year: 2021, month: 5\n",
      "Executing year: 2021, month: 6\n",
      "Executing year: 2021, month: 7\n",
      "Executing year: 2021, month: 8\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/home/cristiandugacicu/projects/personal/de-zoomcamp/course5/notebooks/data/raw/green/2021/*2021_8.*;",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-bfc3f62ffa2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Executing year: {}, month: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#         print(\"data/raw/green/{year}/*{year}_{month}.*\".format(year=year, month=month))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdf_green\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myellow_schema\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/raw/green/{year}/*{year}_{month}.*\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdf_green\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/pq/green/{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristiandugacicu/.local/lib/python2.7/site-packages/pyspark/sql/readwriter.pyc\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristiandugacicu/.local/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristiandugacicu/.local/lib/python2.7/site-packages/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cristiandugacicu/.local/lib/python2.7/site-packages/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/home/cristiandugacicu/projects/personal/de-zoomcamp/course5/notebooks/data/raw/green/2021/*2021_8.*;"
     ]
    }
   ],
   "source": [
    "for year in (2020, 2021):\n",
    "    for month in range(1,13):\n",
    "        print(\"Executing year: {}, month: {}\".format(year,month))\n",
    "#         print(\"data/raw/green/{year}/*{year}_{month}.*\".format(year=year, month=month))\n",
    "        df_green = spark.read \\\n",
    "          .option(\"header\", \"true\") \\\n",
    "          .schema(yellow_schema) \\\n",
    "          .csv(\"data/raw/green/{year}/*{year}_{month}.*\".format(year=year,month=month))\n",
    "\n",
    "        df_green \\\n",
    "            .repartition(4) \\\n",
    "            .write \\\n",
    "            .parquet(\"data/pq/green/{}/{}\".format(year,month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+---------------+-------------+------------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+-------------------+-------------------+---------------+-------------+------------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       1|2020-01-06 06:40:20|2020-01-06 06:42:06|              1|          0.6|                 1|      null|         164|         170|           1|        4.0|  2.5|    0.5|       1.8|         0.0|                  0.3|         9.1|                 2.5|\n",
      "|       2|2020-01-23 18:26:38|2020-01-23 18:48:25|              1|         5.68|                 1|      null|          13|         107|           1|       21.5|  1.0|    0.5|      5.16|         0.0|                  0.3|       30.96|                 2.5|\n",
      "|       1|2020-01-05 09:26:13|2020-01-05 09:43:55|              1|          8.4|                 1|      null|          48|         247|           1|       25.0|  2.5|    0.5|       5.0|         0.0|                  0.3|        33.3|                 2.5|\n",
      "|       2|2020-01-10 13:41:11|2020-01-10 13:52:06|              2|         0.98|                 1|      null|         107|         170|           1|        8.0|  0.0|    0.5|      3.39|         0.0|                  0.3|       14.69|                 2.5|\n",
      "|       1|2020-01-12 14:53:31|2020-01-12 15:17:32|              1|          7.6|                 1|      null|          33|         140|           1|       25.0|  2.5|    0.5|      5.65|         0.0|                  0.3|       33.95|                 2.5|\n",
      "|       1|2020-01-16 21:59:49|2020-01-16 22:09:27|              1|          2.4|                 1|      null|         229|          75|           1|       10.0|  3.0|    0.5|      2.75|         0.0|                  0.3|       16.55|                 2.5|\n",
      "|       2|2020-01-05 17:44:27|2020-01-05 17:49:59|              1|         1.17|                 1|      null|          90|         125|           1|        6.0|  0.0|    0.5|       1.4|         0.0|                  0.3|        10.7|                 2.5|\n",
      "|       1|2020-01-09 17:47:13|2020-01-09 18:00:33|              1|          0.9|                 1|      null|         163|         229|           1|        9.0|  3.5|    0.5|       1.5|         0.0|                  0.3|        14.8|                 2.5|\n",
      "|       2|2020-01-01 09:31:02|2020-01-01 09:32:51|              1|         0.43|                 1|      null|          41|          41|           2|        3.5|  0.0|    0.5|       0.0|         0.0|                  0.3|         4.3|                 0.0|\n",
      "|       2|2020-01-23 21:19:40|2020-01-23 21:32:42|              1|         6.36|                 1|      null|          97|         226|           1|       19.0|  0.5|    0.5|       2.5|         0.0|                  0.3|        22.8|                 0.0|\n",
      "|       1|2020-01-19 16:28:47|2020-01-19 16:35:22|              1|          0.9|                 1|      null|         239|         142|           1|        6.0|  2.5|    0.5|      1.02|         0.0|                  0.3|       10.32|                 2.5|\n",
      "|       1|2020-01-11 15:01:50|2020-01-11 15:14:29|              1|          2.0|                 1|      null|         164|         236|           1|       10.0|  2.5|    0.5|      2.65|         0.0|                  0.3|       15.95|                 2.5|\n",
      "|       2|2020-01-23 07:46:28|2020-01-23 08:32:36|              2|         9.45|                 1|      null|         138|         239|           1|       35.5|  0.0|    0.5|      8.98|        6.12|                  0.3|        53.9|                 2.5|\n",
      "|       2|2020-01-24 21:17:12|2020-01-24 21:39:55|              1|         5.65|                 1|      null|          79|          97|           1|       20.5|  0.5|    0.5|      4.86|         0.0|                  0.3|       29.16|                 2.5|\n",
      "|       2|2020-01-17 20:27:49|2020-01-18 20:09:48|              2|         0.71|                 1|      null|         161|         233|           1|        7.0|  0.5|    0.5|      3.24|         0.0|                  0.3|       14.04|                 2.5|\n",
      "|       2|2020-01-22 13:25:52|2020-01-22 13:53:02|              1|         6.05|                 1|      null|         238|          90|           2|       23.5|  0.0|    0.5|       0.0|         0.0|                  0.3|        26.8|                 2.5|\n",
      "|       2|2020-01-06 05:49:16|2020-01-06 05:52:47|              3|         0.86|                 1|      null|         162|         137|           1|        5.0|  0.5|    0.5|       2.2|         0.0|                  0.3|        11.0|                 2.5|\n",
      "|       2|2020-01-21 15:41:27|2020-01-21 15:52:25|              1|         1.45|                 1|      null|         246|         234|           1|        8.0|  0.0|    0.5|      2.26|         0.0|                  0.3|       13.56|                 2.5|\n",
      "|       2|2020-01-27 07:41:31|2020-01-27 07:46:09|              1|         0.99|                 1|      null|         237|         236|           1|        5.5|  0.0|    0.5|      1.32|         0.0|                  0.3|       10.12|                 2.5|\n",
      "|       2|2020-01-27 08:37:03|2020-01-27 08:43:51|              1|         1.13|                 1|      null|         140|         237|           2|        6.5|  0.0|    0.5|       0.0|         0.0|                  0.3|         9.8|                 2.5|\n",
      "+--------+-------------------+-------------------+---------------+-------------+------------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yellow columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Green columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_yellow_pq = spark.read.parquet(\"data/pq/yellow/*/*/*\") \\\n",
    "      .withColumnRenamed(\"tpep_pickup_datetime\", \"pickup_datetime\") \\\n",
    "      .withColumnRenamed(\"tpep_dropoff_datetime\", \"dropoff_datetime\")\n",
    "\n",
    "df_green_pq = spark.read.parquet(\"data/pq/green/*/*/*\") \\\n",
    "    .withColumnRenamed(\"tpep_pickup_datetime\", \"pickup_datetime\") \\\n",
    "    .withColumnRenamed(\"tpep_dropoff_datetime\", \"dropoff_datetime\")\n",
    "\n",
    "df_yellow_pq.show()\n",
    "df_yellow_pq.printSchema()\n",
    "\n",
    "display(\"Yellow columns:\", df_yellow_pq.columns)\n",
    "display(\"Green columns:\", df_green_pq.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# set(df_yellow_pq.columns) && set(df_green_pq.columns)\n",
    "common_collumns = []\n",
    "\n",
    "for col in df_green_pq.columns:\n",
    "    if col in df_yellow_pq.columns:\n",
    "        common_collumns.append(col)\n",
    "        \n",
    "display(common_collumns) \n",
    "\n",
    "\n",
    "df_yellow_sel = df_yellow_pq.select(common_collumns) \\\n",
    "  .withColumn(\"service_type\", F.lit(\"yellow\")) \n",
    "    \n",
    "df_green_sel = df_green_pq.select(common_collumns) \\\n",
    "  .withColumn(\"service_type\", F.lit(\"green\"))\n",
    "\n",
    "#union\n",
    "df_trips_data = df_green_sel.unionAll(df_yellow_sel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|service_type|   count|\n",
      "+------------+--------+\n",
      "|       green| 2304517|\n",
      "|      yellow|39649199|\n",
      "+------------+--------+\n",
      "\n",
      "+------------+--------+\n",
      "|service_type|count(1)|\n",
      "+------------+--------+\n",
      "|       green| 2304517|\n",
      "|      yellow|39649199|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_trips_data.groupBy(\"service_type\").count().show()\n",
    "\n",
    "# expect\n",
    "# green 2304517\n",
    "# yellow 39649199\n",
    "\n",
    "\n",
    "# make dataFrame a tabe\n",
    "df_trips_data.registerTempTable(\"trips_data\")\n",
    "\n",
    "spark \\\n",
    "  .sql(\"\"\"\n",
    "    SELECT service_type, count(1)\n",
    "    FROM trips_data \n",
    "    GROUP BY service_type;\n",
    "    \"\"\") \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Reveneue groupings:\n",
    "    \n",
    "    PULocationID AS revenue_zone,\n",
    "    \n",
    "    -- data for each month:\n",
    "    date_trunc('month', pickup_datetime) AS revenue_month, \n",
    "    \n",
    "    service_type, \n",
    "\n",
    "    -- Revenue calculation \n",
    "    SUM(fare_amount) AS revenue_monthly_fare,\n",
    "    SUM(extra) AS revenue_monthly_extra,\n",
    "    SUM(mta_tax) AS revenue_monthly_mta_tax,\n",
    "    SUM(tip_amount) AS revenue_monthly_tip_amount,\n",
    "    SUM(tolls_amount) AS revenue_monthly_tolls_amount,\n",
    "    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,\n",
    "    SUM(total_amount) AS revenue_monthly_total_amount,\n",
    "    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,\n",
    "\n",
    "    -- Additional calculations\n",
    "    AVG(passenger_count) AS avg_montly_passenger_count,\n",
    "    AVG(trip_distance) AS avg_montly_trip_distance\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY\n",
    "    1, 2, 3\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result \\\n",
    "    .coalesce(1) \\  #redice number of partitions to 1\n",
    "    .write.parquet('data/report/revenue/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP\n",
    "df_yellow_pq2 = spark.read.parquet(\"data/pq/yellow/*/*\") \\\n",
    "    .withColumnRenamed(\"tpep_pickup_datetime\", \"pickup_datetime\") \\\n",
    "    .withColumnRenamed(\"tpep_dropoff_datetime\", \"dropoff_datetime\")\n",
    "\n",
    "\n",
    "# make dataFrame a tabe\n",
    "df_yellow_pq2.registerTempTable(\"yellow_data2\")\n",
    "\n",
    "df_yellow_revenue = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  date_trunc('hour', pickup_datetime) AS hour,\n",
    "  PULocationID AS zone,\n",
    "  \n",
    "  SUM(total_amount) AS amount,\n",
    "  COUNT(1) AS number_records\n",
    "FROM\n",
    "  yellow_data2\n",
    "WHERE\n",
    "  pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "  1, 2\n",
    "ORDER BY\n",
    "  1, 2\n",
    "\"\"\")#.show()\n",
    "\n",
    "df_yellow_revenue.repartition(20).write.parquet('data/report/revenue/yellow', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP\n",
    "df_green_pq2 = spark.read.parquet(\"data/pq/green/*/*\") \\\n",
    "    .withColumnRenamed(\"tpep_pickup_datetime\", \"pickup_datetime\") \\\n",
    "    .withColumnRenamed(\"tpep_dropoff_datetime\", \"dropoff_datetime\")\n",
    "\n",
    "\n",
    "# make dataFrame a tabe\n",
    "df_green_pq2.registerTempTable(\"green_data2\")\n",
    "\n",
    "df_green_revenue = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  date_trunc('hour', pickup_datetime) AS hour,\n",
    "  PULocationID AS zone,\n",
    "  \n",
    "  SUM(total_amount) AS amount,\n",
    "  COUNT(1) AS number_records\n",
    "FROM\n",
    "  green_data2\n",
    "WHERE\n",
    "  pickup_datetime >= '2020-01-01 00:00:00'\n",
    "GROUP BY\n",
    "  1, 2\n",
    "\"\"\") #.show()\n",
    "\n",
    "df_green_revenue.repartition(20).write.parquet('data/report/revenue/green', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JOIN\n",
    "df_yellow_revenue_temp = df_yellow_revenue \\\n",
    "  .withColumnRenamed('amount', 'yellow_amount') \\\n",
    "  .withColumnRenamed('number_records', 'yellow_number_records') \\\n",
    "\n",
    "df_green_revenue_temp = df_green_revenue \\\n",
    "  .withColumnRenamed('amount', 'green_amount') \\\n",
    "  .withColumnRenamed('number_records', 'green_number_records') \\\n",
    "\n",
    "\n",
    "df_join = df_green_revenue_temp.join(df_yellow_revenue_temp, on=['hour', 'zone'], how='outer')\n",
    "# df_join.show()\n",
    "\n",
    "df_join.write.parquet('data/report/revenue/total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN small file\n",
    "df_zones = spark.read.parquet('zones/')\n",
    "df_result = df_join.join(df_zones, df_join.zone == df_zones.LocationID)\n",
    "df_result.drop('LocationID', 'zone').write.parquet('tmp/revenue-zones')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
